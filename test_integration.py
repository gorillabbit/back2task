#!/usr/bin/env python3
"""
Back2Task MVP Integration Test
å®Œå…¨ãªçµ±åˆãƒ†ã‚¹ãƒˆã¨ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import time
import requests
from typing import Dict

# å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from api.services.llm import LLMService
from ui.notifications import NotificationService, NotificationLevel
from watchers.pump import EventPump


class Back2TaskIntegrationTest:
    """Back2Taskçµ±åˆãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.api_url = "http://localhost:5577"
        # LM Studio Local Server (OpenAI äº’æ›) ã‚’æ—¢å®šã«çµ±ä¸€
        self.llm_url = "http://localhost:1234"
        self.test_results = {}

    def test_api_availability(self) -> bool:
        """APIå¯ç”¨æ€§ãƒ†ã‚¹ãƒˆ"""
        print("=== APIå¯ç”¨æ€§ãƒ†ã‚¹ãƒˆ ===")
        try:
            response = requests.get(f"{self.api_url}/status", timeout=5)
            if response.status_code == 200:
                print("âœ“ FastAPI ã‚µãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨å¯èƒ½")
                return True
            else:
                print(f"âŒ FastAPI ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ FastAPI ã‚µãƒ¼ãƒãƒ¼ã«æŽ¥ç¶šã§ãã¾ã›ã‚“: {e}")
            print(
                "ãƒ’ãƒ³ãƒˆ: uvicorn api.main:app --reload --port 5577 ã§èµ·å‹•ã—ã¦ãã ã•ã„"
            )
            return False

    def test_llm_availability(self) -> bool:
        """LLMå¯ç”¨æ€§ãƒ†ã‚¹ãƒˆ"""
        print("\n=== LLMå¯ç”¨æ€§ãƒ†ã‚¹ãƒˆ ===")
        try:
            response = requests.get(f"{self.llm_url}/v1/models", timeout=5)
            if response.status_code == 200:
                models = response.json()
                print("âœ“ LLMã‚µãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨å¯èƒ½")
                print(f"åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«: {[m['id'] for m in models.get('data', [])]}")
                return True
            else:
                print(f"âŒ LLMã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ LLMã‚µãƒ¼ãƒãƒ¼ã«æŽ¥ç¶šã§ãã¾ã›ã‚“: {e}")
            print("ãƒ’ãƒ³ãƒˆ: LM Studio ã® Local Server ã‚’èµ·å‹•ã—ã¦ãã ã•ã„ï¼ˆä¾‹: http://localhost:1234/v1ï¼‰")
            print("  1) ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆä¾‹: google/gemma-3-4bï¼‰")
            print("  2) Local Server ã‚’èµ·å‹•ï¼ˆOpenAI äº’æ› APIï¼‰")
            return False

    def test_session_lifecycle(self) -> bool:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒ†ã‚¹ãƒˆ"""
        print("\n=== ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒ†ã‚¹ãƒˆ ===")
        try:
            # 1. ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
            start_payload = {
                "task_id": "integration_test",
                "minutes": 1,  # 1åˆ†ã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³
            }
            response = requests.post(f"{self.api_url}/focus/start", json=start_payload)
            if response.status_code != 200:
                print(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹å¤±æ•—: {response.status_code}")
                return False
            print("âœ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æˆåŠŸ")

            # 2. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
            response = requests.get(f"{self.api_url}/status")
            if response.status_code != 200:
                print(f"âŒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—å¤±æ•—: {response.status_code}")
                return False

            status = response.json()
            if status.get("current_task", {}).get("id") != "integration_test":
                print(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“: {status}")
                return False
            print("âœ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç¢ºèªæˆåŠŸ")

            # 3. ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡ãƒ†ã‚¹ãƒˆ
            test_events = [
                {  # ç”Ÿç”£çš„ãªã‚¤ãƒ™ãƒ³ãƒˆ
                    "active_app": "Code.exe",
                    "title": "test.py - VSCode",
                    "url": "",
                    "idle_ms": 1000,
                    "ocr": "def test_function():",
                    "phone_detected": False,
                    "phone": "",
                },
                {  # è„±ç·šã‚¤ãƒ™ãƒ³ãƒˆ
                    "active_app": "chrome.exe",
                    "title": "YouTube - Google Chrome",
                    "url": "https://youtube.com",
                    "idle_ms": 500,
                    "ocr": "ãŠã™ã™ã‚å‹•ç”»",
                    "phone_detected": False,
                    "phone": "",
                },
            ]

            for i, event in enumerate(test_events):
                response = requests.post(f"{self.api_url}/events", json=event)
                if response.status_code != 200:
                    print(f"âŒ ã‚¤ãƒ™ãƒ³ãƒˆ{i + 1}é€ä¿¡å¤±æ•—: {response.status_code}")
                    return False

                result = response.json()
                expected_productive = i == 0  # æœ€åˆã¯ç”Ÿç”£çš„ã€2ç•ªç›®ã¯éžç”Ÿç”£çš„
                if result.get("productive") != expected_productive:
                    print(f"âŒ ã‚¤ãƒ™ãƒ³ãƒˆ{i + 1}ã®ç”Ÿç”£æ€§åˆ¤å®šãŒæœŸå¾…ã¨ç•°ãªã‚Šã¾ã™: {result}")
                    return False

                print(
                    f"âœ“ ã‚¤ãƒ™ãƒ³ãƒˆ{i + 1}é€ä¿¡ãƒ»åˆ¤å®šæˆåŠŸ (ç”Ÿç”£çš„: {result['productive']})"
                )

            return True

        except Exception as e:
            print(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return False

    def test_llm_integration(self) -> bool:
        """LLMçµ±åˆãƒ†ã‚¹ãƒˆ"""
        print("\n=== LLMçµ±åˆãƒ†ã‚¹ãƒˆ ===")
        try:
            llm_service = LLMService(base_url=self.llm_url)

            # LLMå¯ç”¨æ€§ç¢ºèª
            if not llm_service.is_available():
                print("âš ï¸  LLMã‚µãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ")

            # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
            test_cases = [
                {
                    "name": "ç”Ÿç”£çš„æ´»å‹•",
                    "observations": {
                        "active_app": "Code.exe",
                        "title": "main.py - VSCode",
                        "url": "",
                        "idle_ms": 1000,
                        "ocr": "def calculate_metrics():",
                        "phone_detected": False,
                        "phone": "",
                    },
                    "expected_action": "quiet",
                },
                {
                    "name": "è»½åº¦ã®è„±ç·š",
                    "observations": {
                        "active_app": "chrome.exe",
                        "title": "Reddit - Programming",
                        "url": "https://reddit.com/r/programming",
                        "idle_ms": 2000,
                        "ocr": "programming news",
                        "phone_detected": False,
                        "phone": "",
                    },
                    "expected_action": "gentle_nudge",
                },
                {
                    "name": "é‡åº¦ã®è„±ç·š",
                    "observations": {
                        "active_app": "chrome.exe",
                        "title": "YouTube - Funny Videos",
                        "url": "https://youtube.com/watch?v=funny",
                        "idle_ms": 1000,
                        "ocr": "funny cat videos",
                        "phone_detected": True,
                        "phone": "jp.youtube",
                    },
                    "expected_action": "strong_nudge",
                },
            ]

            for case in test_cases:
                policy = llm_service.decide_nudging_policy(
                    "ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯", case["observations"]
                )

                print(f"ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: {case['name']}")
                print(f"  åˆ¤å®š: {policy.action}")
                print(f"  ç†ç”±: {policy.reason}")
                if policy.tip:
                    print(f"  ãƒ’ãƒ³ãƒˆ: {policy.tip}")
                print(f"  ä¿¡é ¼åº¦: {policy.confidence}")

                # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒé©åˆ‡ãªç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
                valid_actions = ["quiet", "gentle_nudge", "strong_nudge"]
                if policy.action not in valid_actions:
                    print(f"âŒ ç„¡åŠ¹ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {policy.action}")
                    return False

                print("âœ“ åˆ¤å®šæˆåŠŸ")

            print("âœ“ LLMçµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")
            return True

        except Exception as e:
            print(f"âŒ LLMçµ±åˆãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return False

    def test_notification_system(self) -> bool:
        """é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
        print("\n=== é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ ===")
        try:
            notification_service = NotificationService()

            print(f"ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {notification_service.platform}")
            capabilities = notification_service.get_capabilities()
            print(f"é€šçŸ¥æ©Ÿèƒ½: {capabilities}")

            # å„ãƒ¬ãƒ™ãƒ«ã®é€šçŸ¥ã‚’ãƒ†ã‚¹ãƒˆ
            test_notifications = [
                (NotificationLevel.INFO, "æƒ…å ±", "ãƒ†ã‚¹ãƒˆç”¨ã®æƒ…å ±é€šçŸ¥ã§ã™"),
                (NotificationLevel.WARNING, "æ³¨æ„", "è»½ã„æ³¨æ„å–šèµ·ã®ãƒ†ã‚¹ãƒˆã§ã™"),
                (NotificationLevel.URGENT, "ç·Šæ€¥", "ç·Šæ€¥é€šçŸ¥ã®ãƒ†ã‚¹ãƒˆã§ã™"),
            ]

            for level, title, message in test_notifications:
                result = notification_service.notify(title, message, level)
                print(f"é€šçŸ¥ãƒ¬ãƒ™ãƒ« {level.value}: {'æˆåŠŸ' if result else 'å¤±æ•—'}")
                time.sleep(1)  # é€šçŸ¥é–“ã®é–“éš”

            # å±¥æ­´ç¢ºèª
            history = notification_service.get_notification_history()
            print(f"é€šçŸ¥å±¥æ­´: {len(history)}ä»¶")

            print("âœ“ é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†")
            return True

        except Exception as e:
            print(f"âŒ é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return False

    def test_watchers_data_collection(self) -> bool:
        """Watchers ãƒ‡ãƒ¼ã‚¿åŽé›†ãƒ†ã‚¹ãƒˆ"""
        print("\n=== Watchers ãƒ‡ãƒ¼ã‚¿åŽé›†ãƒ†ã‚¹ãƒˆ ===")
        try:
            event_pump = EventPump(api_url=f"{self.api_url}/events")

            # ãƒ‡ãƒ¼ã‚¿åŽé›†ãƒ†ã‚¹ãƒˆ
            print("ãƒ‡ãƒ¼ã‚¿åŽé›†ä¸­...")
            event_data = event_pump.collect_all_data()

            required_fields = [
                "active_app",
                "title",
                "idle_ms",
                "ocr",
                "phone_detected",
            ]
            for field in required_fields:
                if field not in event_data:
                    print(f"âŒ å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³: {field}")
                    return False

            print("âœ“ å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæ­£å¸¸ã«åŽé›†ã•ã‚Œã¾ã—ãŸ")
            print(f"  ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ—ãƒª: {event_data.get('active_app')}")
            print(f"  ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¿ã‚¤ãƒˆãƒ«: {event_data.get('title', '')[:50]}")
            print(f"  ã‚¢ã‚¤ãƒ‰ãƒ«æ™‚é–“: {event_data.get('idle_ms')}ms")
            print(f"  OCRãƒ†ã‚­ã‚¹ãƒˆ: {len(event_data.get('ocr', ''))}æ–‡å­—")
            print(f"  ã‚¹ãƒžãƒ›æ¤œå‡º: {event_data.get('phone_detected')}")

            # ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆç¢ºèª
            status = event_pump.get_status()
            total_errors = sum(status["error_counts"].values())
            if total_errors > 3:
                print(f"âš ï¸  å¤šãã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™: {status['error_counts']}")
            else:
                print("âœ“ ã‚¨ãƒ©ãƒ¼æ•°ã¯æ­£å¸¸ç¯„å›²å†…ã§ã™")

            event_pump.stop()
            print("âœ“ Watchers ãƒ‡ãƒ¼ã‚¿åŽé›†ãƒ†ã‚¹ãƒˆå®Œäº†")
            return True

        except Exception as e:
            print(f"âŒ Watchers ãƒ‡ãƒ¼ã‚¿åŽé›†ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return False

    def test_end_to_end_scenario(self) -> bool:
        """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
        print("\n=== ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ ===")
        try:
            # 1. ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
            print("1. ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹...")
            start_payload = {"task_id": "e2e_test", "minutes": 1}
            response = requests.post(f"{self.api_url}/focus/start", json=start_payload)
            assert response.status_code == 200

            # 2. LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
            print("2. LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–...")
            llm_service = LLMService(base_url=self.llm_url)

            # 3. é€šçŸ¥ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
            print("3. é€šçŸ¥ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–...")
            notification_service = NotificationService()

            # 4. ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: ç”Ÿç”£çš„ãªä½œæ¥­ â†’ è„±ç·š â†’ é€šçŸ¥ â†’ å¾©å¸°
            print("4. ä½œæ¥­ã‚·ãƒŠãƒªã‚ªã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³...")

            scenarios = [
                {
                    "description": "ç”Ÿç”£çš„ãªä½œæ¥­",
                    "event": {
                        "active_app": "Code.exe",
                        "title": "project.py - VSCode",
                        "url": "",
                        "idle_ms": 1000,
                        "ocr": "class ProductivityTracker:",
                        "phone_detected": False,
                        "phone": "",
                    },
                    "expected_productive": True,
                },
                {
                    "description": "è„±ç·šé–‹å§‹",
                    "event": {
                        "active_app": "chrome.exe",
                        "title": "YouTube - Music Videos",
                        "url": "https://youtube.com/watch?v=music",
                        "idle_ms": 500,
                        "ocr": "music video playlist",
                        "phone_detected": False,
                        "phone": "",
                    },
                    "expected_productive": False,
                },
                {
                    "description": "ã‚¹ãƒžãƒ›ã§è¿½åŠ ã®è„±ç·š",
                    "event": {
                        "active_app": "chrome.exe",
                        "title": "YouTube - Music Videos",
                        "url": "https://youtube.com/watch?v=music",
                        "idle_ms": 1000,
                        "ocr": "music video playlist",
                        "phone_detected": True,
                        "phone": "jp.youtube",
                    },
                    "expected_productive": False,
                },
            ]

            for i, scenario in enumerate(scenarios):
                print(f"  ã‚·ãƒŠãƒªã‚ª {i + 1}: {scenario['description']}")

                # ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡
                response = requests.post(
                    f"{self.api_url}/events", json=scenario["event"]
                )
                assert response.status_code == 200

                result = response.json()
                actual_productive = result.get("productive")

                print(
                    f"    ç”Ÿç”£æ€§åˆ¤å®š: {actual_productive} (æœŸå¾…: {scenario['expected_productive']})"
                )

                if actual_productive != scenario["expected_productive"]:
                    print("    âš ï¸  åˆ¤å®šãŒæœŸå¾…ã¨ç•°ãªã‚Šã¾ã™")

                # LLMã§nudgingåˆ¤å®š
                policy = llm_service.decide_nudging_policy(
                    "e2e_test", scenario["event"]
                )
                print(f"    Nudging: {policy.action} - {policy.reason}")

                # éžç”Ÿç”£çš„ãªå ´åˆã¯é€šçŸ¥
                if not actual_productive:
                    if policy.action == "gentle_nudge":
                        notification_service.notify(
                            "è»½ã„æ³¨æ„",
                            policy.tip or "ä½œæ¥­ã«æˆ»ã‚Šã¾ã—ã‚‡ã†",
                            NotificationLevel.WARNING,
                        )
                    elif policy.action == "strong_nudge":
                        notification_service.notify(
                            "å¼·ã„æ³¨æ„",
                            policy.tip or "ä»Šã¯ä½œæ¥­æ™‚é–“ã§ã™ï¼",
                            NotificationLevel.URGENT,
                        )

                time.sleep(2)  # ã‚·ãƒŠãƒªã‚ªé–“ã®å¾…æ©Ÿ

            # 5. ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç¢ºèª
            print("5. æœ€çµ‚ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç¢ºèª...")
            response = requests.get(f"{self.api_url}/status")
            assert response.status_code == 200

            final_status = response.json()
            print(f"  ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯: {final_status.get('current_task', {}).get('id')}")
            print(
                f"  ç©ç®—æ™‚é–“: {final_status.get('current_task', {}).get('accum', 0)}ç§’"
            )
            print(
                f"  ç¾åœ¨ã®çŠ¶æ…‹: {'ç”Ÿç”£çš„' if final_status.get('productive') else 'éžç”Ÿç”£çš„'}"
            )

            print("âœ“ ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆå®Œäº†")
            return True

        except Exception as e:
            print(f"âŒ ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            import traceback

            traceback.print_exc()
            return False

    def run_all_tests(self) -> Dict[str, bool]:
        """å…¨ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print("ðŸŽ¯ Back2Task MVP çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹\n")

        tests = [
            ("APIå¯ç”¨æ€§", self.test_api_availability),
            ("LLMå¯ç”¨æ€§", self.test_llm_availability),
            ("ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«", self.test_session_lifecycle),
            ("LLMçµ±åˆ", self.test_llm_integration),
            ("é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ", self.test_notification_system),
            ("Watchersãƒ‡ãƒ¼ã‚¿åŽé›†", self.test_watchers_data_collection),
            ("ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã‚·ãƒŠãƒªã‚ª", self.test_end_to_end_scenario),
        ]

        results = {}

        for test_name, test_func in tests:
            try:
                result = test_func()
                results[test_name] = result
                if result:
                    print(f"âœ… {test_name}: æˆåŠŸ")
                else:
                    print(f"âŒ {test_name}: å¤±æ•—")
            except Exception as e:
                print(f"âŒ {test_name}: ä¾‹å¤–ç™ºç”Ÿ - {e}")
                results[test_name] = False

            print()  # ç©ºè¡Œ

        return results

    def print_summary(self, results: Dict[str, bool]):
        """ãƒ†ã‚¹ãƒˆçµæžœã‚µãƒžãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print("=" * 60)
        print("ðŸ“Š ãƒ†ã‚¹ãƒˆçµæžœã‚µãƒžãƒªãƒ¼")
        print("=" * 60)

        passed = sum(results.values())
        total = len(results)

        for test_name, result in results.items():
            status = "âœ… PASS" if result else "âŒ FAIL"
            print(f"{test_name}: {status}")

        print("-" * 60)
        print(f"åˆè¨ˆ: {passed}/{total} ãƒ†ã‚¹ãƒˆé€šéŽ ({passed / total * 100:.1f}%)")

        if passed == total:
            print("ðŸŽ‰ å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼Back2Task MVPã¯å‹•ä½œå¯èƒ½ã§ã™ã€‚")
        else:
            print("âš ï¸  ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            print("\nðŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:")

            if not results.get("APIå¯ç”¨æ€§"):
                print(
                    "- FastAPIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•: uvicorn api.main:app --reload --port 5577"
                )

            if not results.get("LLMå¯ç”¨æ€§"):
                print("- LM Studio ã® Local Server ã‚’èµ·å‹•ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆä¾‹: google/gemma-3-4bï¼‰")
                print("  æŽ¥ç¶šç¢ºèª: curl http://localhost:1234/v1/models")

            if not results.get("Watchersãƒ‡ãƒ¼ã‚¿åŽé›†"):
                print(
                    "- å¿…è¦ãªä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install opencv-python pytesseract ultralytics"
                )

        print("=" * 60)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    test_runner = Back2TaskIntegrationTest()
    results = test_runner.run_all_tests()
    test_runner.print_summary(results)

    # å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸã®å ´åˆã¯0ã€å¤±æ•—ãŒã‚ã‚Œã°1ã§çµ‚äº†
    success_rate = sum(results.values()) / len(results)
    exit(0 if success_rate >= 0.8 else 1)


if __name__ == "__main__":
    main()
